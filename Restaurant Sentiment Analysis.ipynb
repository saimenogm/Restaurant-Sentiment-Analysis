{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59056081-3dce-403f-a963-9d0a0cdb37ba",
   "metadata": {},
   "source": [
    "# Restaurant Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c62d8-b2fa-40b5-896b-a879b78aaa55",
   "metadata": {},
   "source": [
    "#### Developers\n",
    "- Simon Manna [Machine Learning & AI Engineer] \n",
    "- Merhawi Tsegay [Machine Learning Engineer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a3938-f7ed-4f8b-aeb5-a6330dfa2b1a",
   "metadata": {},
   "source": [
    "#### Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0193a408-1b37-4bdb-8587-eb87c43c1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6261d151-73bd-4136-a047-4709600805f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "data = pd.read_csv('C:\\\\datasets\\\\restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b0f02b-5498-467a-9d98-890252eff411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2220 entries, 0 to 2219\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Review  2220 non-null   object \n",
      " 1   Liked   2117 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 34.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8296af-e3cf-4757-837a-9ecdd7ab1400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2220, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9ff3af-f4a3-481b-b335-b854f069be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review      0\n",
      "Liked     103\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a96e7dc-2bbf-49c5-a3e7-76345881e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null values\n",
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc60de6-ecb8-4638-9041-74588023f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the small or medium spacy English corpus\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5160246-807a-47f5-83b8-843178416147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token POS Lemma\n",
      "Wow INTJ wow\n",
      "... PUNCT ...\n",
      "Loved VERB love\n",
      "this DET this\n",
      "place NOUN place\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "# check the first Row Review, to see how the data looks like.\n",
    "doc = nlp(data.iloc[0]['Review'])\n",
    "\n",
    "print(f\"Token\",\"POS\",\"Lemma\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.lemma_) #, spacy.spacy_explain(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0f5564-6927-49ee-9a8b-c91bc0792147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x000001C6905B20E0>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x000001C6907B4700>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x000001C6905B7450>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x000001C6904F2440>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x000001C6908754C0>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x000001C6905AD690>)]\n"
     ]
    }
   ],
   "source": [
    "# Check the spacy process pipeline\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f68f87-aeb9-4d7f-a017-71505253720f",
   "metadata": {},
   "source": [
    "#### Preprocess and Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c9b70b-3b09-4bd7-aa4b-be81f90ee18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Non Alphanumeric words\n",
    "data['Review'] = data['Review'].apply(lambda x: re.sub(r'[\\W_]+', ' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36231352-b381-47a9-b65c-bcd7da9cb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the text into lower case\n",
    "data['Review'] = data['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc74abe-7dec-4bab-9284-8a6b90cd5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "def remove_stop_words(doc):\n",
    "    return \" \".join([token.text for token in nlp(doc) if not token.is_stop])\n",
    "\n",
    "data['Review'] = data['Review'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07e44d58-88a4-4e66-b984-22d116328d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the words to their base/root word\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "data['Review'] = data['Review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282322cc-68d9-4391-b430-7249f8907b0d",
   "metadata": {},
   "source": [
    "#### Feature Extraction and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a5293c2-b1bf-43a6-93bf-76bac1790f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2117, 1806)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(data['Review']).toarray()\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28c76c4c-5773-4032-b67e-be8b14f342f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare y(target value)\n",
    "y = data['Liked']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24ddb36-cea8-4826-95fd-fc854885fd57",
   "metadata": {},
   "source": [
    "#### Prepare Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65684584-df8d-4123-86b7-89779c71288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01408ef-88e6-4e41-9c5f-8527a931eb57",
   "metadata": {},
   "source": [
    "#### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39f0f442-a5d0-4dfe-beb8-22413c036cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Model Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c3a0fd5-801b-470e-8ba8-5c9a0337977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize algorithms\n",
    "logistic_classifier = LogisticRegression()\n",
    "multinomial_classifier = MultinomialNB()\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "svm_classifier = SVC()\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Model Algorithms List\n",
    "algorithms = [logistic_classifier, multinomial_classifier, decision_tree_classifier, \n",
    "              svm_classifier, random_forest_classifier, xgb_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cafd10df-bc5c-49c2-aee5-448f8f6b401b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Accuracy: 0.875\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.96      0.88       194\n",
      "         1.0       0.96      0.80      0.87       230\n",
      "\n",
      "    accuracy                           0.88       424\n",
      "   macro avg       0.88      0.88      0.87       424\n",
      "weighted avg       0.89      0.88      0.87       424\n",
      "\n",
      "MultinomialNB\n",
      "Accuracy: 0.8726415094339622\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.86      0.86       194\n",
      "         1.0       0.88      0.89      0.88       230\n",
      "\n",
      "    accuracy                           0.87       424\n",
      "   macro avg       0.87      0.87      0.87       424\n",
      "weighted avg       0.87      0.87      0.87       424\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Accuracy: 0.8632075471698113\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.89      0.86       194\n",
      "         1.0       0.90      0.84      0.87       230\n",
      "\n",
      "    accuracy                           0.86       424\n",
      "   macro avg       0.86      0.87      0.86       424\n",
      "weighted avg       0.87      0.86      0.86       424\n",
      "\n",
      "SVC\n",
      "Accuracy: 0.8726415094339622\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.96      0.87       194\n",
      "         1.0       0.96      0.80      0.87       230\n",
      "\n",
      "    accuracy                           0.87       424\n",
      "   macro avg       0.88      0.88      0.87       424\n",
      "weighted avg       0.89      0.87      0.87       424\n",
      "\n",
      "RandomForestClassifier\n",
      "Accuracy: 0.8702830188679245\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.96      0.87       194\n",
      "         1.0       0.96      0.80      0.87       230\n",
      "\n",
      "    accuracy                           0.87       424\n",
      "   macro avg       0.88      0.88      0.87       424\n",
      "weighted avg       0.88      0.87      0.87       424\n",
      "\n",
      "XGBClassifier\n",
      "Accuracy: 0.8514150943396226\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.95      0.85       194\n",
      "         1.0       0.95      0.77      0.85       230\n",
      "\n",
      "    accuracy                           0.85       424\n",
      "   macro avg       0.86      0.86      0.85       424\n",
      "weighted avg       0.87      0.85      0.85       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for algorithm in algorithms:\n",
    "    print(f\"{algorithm.__class__.__name__}\")\n",
    "    # Train the Algorithm\n",
    "    algorithm.fit(X_train,y_train)\n",
    "    # Make Prediction\n",
    "    y_pred = algorithm.predict(X_test)\n",
    "    # Measure Accuracy\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    # Classification Report\n",
    "    print(\"Classification Report: \")\n",
    "    eval_result = classification_report(y_test, y_pred)\n",
    "    print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13607011-0ccf-4451-80c2-73fe6f9f326a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
